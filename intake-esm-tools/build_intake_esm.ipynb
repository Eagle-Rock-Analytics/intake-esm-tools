{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 📚 How to Build an Intake-ESM Catalog  \n",
    "\n",
    "**Author:** Nicole Keeney  \n",
    "**Creation Date:** March 2025  \n",
    "**Last Modified:** N/A  \n",
    "\n",
    "## 📖 Overview  \n",
    "This notebook provides a step-by-step guide to building an **Intake-ESM** catalog for zarrs in an s3 bucket, including how to use `ecgtools` to create a custom parser and structure datasets for use with `intake-esm`.  \n",
    "\n",
    "## 🔗 Useful Resources  \n",
    "- 📄 **Building a Custom Parser with `ecgtools`**:  \n",
    "  [ecgtools documentation](https://ecgtools.readthedocs.io/en/latest/how-to/use-a-custom-parser.html)  \n",
    "- 📄 **Creating a Catalog with `intake-esm`**:  \n",
    "  [Intake-ESM documentation](https://intake-esm.readthedocs.io/en/stable/how-to/build-a-catalog-from-timeseries-files.html)  \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 144,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import s3fs \n",
    "import traceback\n",
    "from tqdm import tqdm\n",
    "from ecgtools import Builder\n",
    "from ecgtools.builder import INVALID_ASSET, TRACEBACK"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 🛠️ Guide to the `ecgtools` Builder Class \n",
    "\n",
    "The primary function of the `Builder` class is to create catalogs from lists of netCDF files or Zarr stores. It \"crawls\" through your data directories for you, looking for file paths using the information you have specified. You can refer to the official documentation [here](https://ecgtools.readthedocs.io/en/latest/reference/index.html#builder), but I'll also provide a brief overview and additional notes below. 📚\n",
    "\n",
    "### 📝 Nicole's notes on the Builder class \n",
    "\n",
    "Let’s say you have an **S3 bucket** named `salsa_cities` 💃, which contains a CSV file and two directories: `new_york` and `miami`. Each of these directories contains **Zarr stores** with climate data specific to their locations. It's important to remember that Zarr stores are **not files**; they are storage structures represented as **directories** in the S3 file system. Each Zarr store consists of several nested directories and metadata files. In this case, `precip/`, `x/`, `y/`, and `time/` are directories within the Zarr store.\n",
    "\n",
    "> **salsa_cities/** <br>\n",
    "  ├── **new_york/** <br>\n",
    "  &nbsp;&nbsp;&nbsp;&nbsp;├── **precip/** <br>\n",
    "  &nbsp;&nbsp;&nbsp;&nbsp;├── **temp/** <br>\n",
    "  &nbsp;&nbsp;&nbsp;&nbsp;├── **x/** <br>\n",
    "  &nbsp;&nbsp;&nbsp;&nbsp;└── **y/** <br>\n",
    "  &nbsp;&nbsp;&nbsp;&nbsp;└── **time/** <br>\n",
    "  &nbsp;&nbsp;&nbsp;&nbsp;└── *.zattrs* <br>\n",
    "  &nbsp;&nbsp;&nbsp;&nbsp;└── *.zgroup* <br>\n",
    "  &nbsp;&nbsp;&nbsp;&nbsp;└── *.zmetadata* <br>\n",
    "  └── **miami/** <br>\n",
    "  &nbsp;&nbsp;&nbsp;&nbsp;├── **precip/** <br>\n",
    "  &nbsp;&nbsp;&nbsp;&nbsp;├── **temp/** <br>\n",
    "  &nbsp;&nbsp;&nbsp;&nbsp;├── **x/** <br>\n",
    "  &nbsp;&nbsp;&nbsp;&nbsp;└── **y/** <br>\n",
    "  &nbsp;&nbsp;&nbsp;&nbsp;└── **time/** <br>\n",
    "  &nbsp;&nbsp;&nbsp;&nbsp;└── *.zattrs* <br>\n",
    "  &nbsp;&nbsp;&nbsp;&nbsp;└── *.zgroup* <br>\n",
    "  &nbsp;&nbsp;&nbsp;&nbsp;└── *.zmetadata* <br>\n",
    "  └── *best_cities_to_salsa_dance.csv* <br>\n",
    "\n",
    "Each Zarr store includes the following structure: \n",
    "\n",
    "- **Data variable directories**: `precip/`, `temp/`\n",
    "- **Spatial and temporal dimension directories**: `x/`, `y/`, `time/`\n",
    "- **Metadata files**: `.zattrs`, `.zgroup`, `.zmetadata`\n",
    "\n",
    "#### 💻 Using the Builder to build a catalog \n",
    "\n",
    "Now, let's use the `Builder` class to build a catalog for the Zarr stores in our bucket:\n",
    "\n",
    "```python\n",
    "builder = Builder(\n",
    "    paths=[\"s3://salsa_cities/\"], # A list of paths to the data; this should be the root directory of your data files.\n",
    "    depth=1, # Maximum depth to crawl for assets.\n",
    "    exclude_patterns=['**/best_cities_to_salsa_dance.csv'], # List of glob patterns to exclude from crawling.\n",
    "    include_patterns=['**/.zmetadata'] # List of glob patterns to include when crawling \n",
    ")\n",
    "```\n",
    "\n",
    "After that, we will \"build\" the catalog using this Builder object and a custom parser function, and then generate a CSV file and JSON file. More information on these steps are in the code. \n",
    "\n",
    "### 🔍 Additional notes on the inputs to Builder \n",
    "- **depth**: How far within the paths above should the Builder search for your files? Say we just want to look for the files in `paths=[\"s3://salsa_cities/new_york/\"]`. In this case, our depth would be 0, because the root directory contains our Zarr store in it. \n",
    "- **exclude_patterns**: We're not interested in the CSV file, so we ignore it when crawling. You can also add directories here using this formatting: `**/another_directory/**`\n",
    "- **include_patterns**: Since Zarrs are stores and not individual files, we need to be a bit clever here.\n",
    "  - We just look at the `.zmetadata` file because it's a terminal file within the root directory of the Zarr store; we don't want the crawler to look into the dimensions or data directories.\n",
    "  - The Builder class isn't really optimized to work with Zarrs, so we need to avoid it crawling into the other directories within the Zarr store. These other directories will contain the metadata files `.zattrs` and `.zgroup`, but not `.zmetadata`; only the root directory has that file. By setting `include_patterns=['/**.zmetadata']`, we are solving two issues: we are ignoring the nested directories within the root directory of the Zarr (`precip`, `x`, `y`, and `time`), and then returning only a single path for each Zarr (the paths for `.zgroup` and `.zattrs` within the root directory are also ignored). 🎯\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 1: Build a custom parser function \n",
    "This function extracts information from the filepath, such that it can be used by the `Builder` to generate the function. For the input filepaths, the path to the zarr will include the `.zmetadata` extension, even though the `path` key in the output dictionary will **not** include this file extension; I realize this is confusing, but it's a hacky way to get around some inflexibility in the `Builder` class when working with zarrs. See the section above for more info: **Additional notes on the inputs to Builder: include_patterns**."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def parse_ae_ren_data(filepath):\n",
    "    \"\"\"\n",
    "    Parses the S3 filepath to extract metadata for climate simulation data.\n",
    "    \n",
    "    Extracts information like installation, simulation model, experiment, \n",
    "    frequency, variable, grid resolution, and the file path (without `.zmetadata`).\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    filepath : str\n",
    "        The S3 URL of the file.\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    dict\n",
    "        A dictionary with parsed metadata:\n",
    "        - installation, activity_id, institution_id, source_id, experiment_id, \n",
    "          table_id, variable_id, grid_label, path.\n",
    "        If parsing fails, returns a dictionary with the error details:\n",
    "        - INVALID_ASSET and TRACEBACK.\n",
    "\n",
    "    Example\n",
    "    -------\n",
    "    >>> parse_ae_ren_data('s3://wfclimres/ERA/WRF/EC-Earth3/experiment/precipitation/variable/zarr/file.zmetadata')\n",
    "    {\n",
    "        \"installation\": \"WRF\",\n",
    "        \"activity_id\": \"WRF\",\n",
    "        \"institution_id\": \"ERA\",\n",
    "        \"source_id\": \"EC-Earth3\",\n",
    "        \"experiment_id\": \"experiment\",\n",
    "        \"table_id\": \"precipitation\",\n",
    "        \"variable_id\": \"variable\",\n",
    "        \"grid_label\": \"zarr\",\n",
    "        \"path\": \"s3://wfclimres/ERA/WRF/EC-Earth3/experiment/precipitation/variable/zarr/file\"\n",
    "    }\n",
    "\n",
    "    Notes\n",
    "    -----\n",
    "    The `try/except` block handles errors in extracting information from the `filepath`. \n",
    "    If the filepath structure does not match the expected format or if any error occurs \n",
    "    while splitting the string, the `except` block will capture the exception and return \n",
    "    a dictionary with the error message and traceback.\n",
    "    \"\"\"\n",
    "    try:\n",
    "        # Get the data info from the filepath\n",
    "        institution_id, installation, source_id, experiment_id, table_id, variable_id, grid_label, _ = filepath.split(\"s3://wfclimres/\")[1].split(\"/\")\n",
    "        # Remove .zmetadata from the filepath, since the actual path to the zarr doesn't include this \n",
    "        filepath = filepath.split(\".zmetadata\")[0]\n",
    "    except Exception as e:\n",
    "        # If an error occurs (e.g., wrong filepath structure), return error details\n",
    "        return {INVALID_ASSET: filepath, TRACEBACK: traceback.format_exc()}\n",
    "    \n",
    "    # Simulation string mapping\n",
    "    simulation_dict = {\n",
    "        \"ec-earth3\": \"EC-Earth3\",\n",
    "        \"mpi-esm1-2-hr\": \"MPI-ESM1-2-HR\",\n",
    "        \"miroc6\": \"MIROC6\",\n",
    "        \"taiesm1\": \"TaiESM1\",\n",
    "        \"era5\": \"ERA5\"\n",
    "    }\n",
    "\n",
    "    # Add filepath info to dictionary\n",
    "    info = {\n",
    "        \"installation\": installation,\n",
    "        \"activity_id\": \"WRF\", \n",
    "        \"institution_id\": \"ERA\",\n",
    "        \"source_id\": simulation_dict[source_id],\n",
    "        \"experiment_id\": experiment_id,\n",
    "        \"table_id\": table_id,\n",
    "        \"variable_id\": variable_id,\n",
    "        \"grid_label\": grid_label,\n",
    "        \"path\": filepath\n",
    "    }\n",
    "    \n",
    "    return info\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 2: Build the catalog \n",
    "Using the custom parser, we will create our Builder object and build the catalog. How this is coded up will depend on various inputs. I'll show some different methods below.<br><br>\n",
    "Each method will use some variation of the following code: \n",
    "```python \n",
    "# Base Builder object \n",
    "b = Builder(paths=[\"s3://path-to-data-directory\"]) \n",
    "\n",
    "# Build the catalog using a custom parsing function (you need to define this function for your unique data structure)\n",
    "b.build(parsing_func=custom_parsing_func)\n",
    "\n",
    "# Exclude invalid assets and removing duplicate entries\n",
    "b.clean_dataframe()\n",
    "\n",
    "# View your build catalog as a dataframe :) \n",
    "b.df\n",
    "```\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Method 1: Feed the Builder allllll the filepaths (no crawling required)\n",
    "The Builder won't do any crawling of your data bucket, because you've oh so kindly fed it all the filepaths it needs. This method requires **you** to do the crawling beforehand to generate a list of these filepaths. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Below, I've written a bunch of code to crawl through the renewables s3 bucket and get filepaths for all the files I want to include in the catalog"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Scanning S3: 100%|██████████| 20/20 [01:05<00:00,  3.26s/query]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total files found: 112\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "fs = s3fs.S3FileSystem()\n",
    "\n",
    "# Use these to filter the s3 bucket \n",
    "installations = [\"pv_distributed\", \"pv_utility\", \"windpower_offshore\", \"windpower_onshore\"]\n",
    "source_ids = [\"ec-earth3\", \"miroc6\", \"mpi-esm1-2-hr\", \"taiesm1\", \"era5\"]\n",
    "\n",
    "# Total iterations for tqdm\n",
    "total_iterations = len(installations) * len(source_ids)\n",
    "\n",
    "filepaths = [] # Store all filepaths here \n",
    "with tqdm(total=total_iterations, desc=\"Scanning S3\", unit=\"query\") as pbar:\n",
    "    for installation in installations:\n",
    "        for source_id in source_ids:\n",
    "            # I think each unique zarr store has a single .zmetadata file associated with it \n",
    "            # Use .zmetadata to grab path to the main zarr store \n",
    "            # Otherwise you get all the random stuff associated with it (variables, coords, etc) since zarr is a directory, not a single file \n",
    "            glob_s3 = fs.glob(f\"s3://wfclimres/era/{installation}/{source_id}/**/*.zmetadata\")\n",
    "            zarr_paths = [\"s3://\"+file.split(\".zmetadata\")[0] for file in glob_s3] # Remove .zmetadata from the path \n",
    "            filepaths += zarr_paths \n",
    "            pbar.update(1)  # Update progress bar\n",
    "\n",
    "print(f\"Total files found: {len(filepaths)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next, feed these filepaths to the Builder. Since these filepaths are already **absolute filepaths**, set the argument ``depth=0``: no crawling required. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 146,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>installation</th>\n",
       "      <th>activity_id</th>\n",
       "      <th>institution_id</th>\n",
       "      <th>source_id</th>\n",
       "      <th>experiment_id</th>\n",
       "      <th>table_id</th>\n",
       "      <th>variable_id</th>\n",
       "      <th>grid_label</th>\n",
       "      <th>path</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>pv_distributed</td>\n",
       "      <td>WRF</td>\n",
       "      <td>ERA</td>\n",
       "      <td>EC-Earth3</td>\n",
       "      <td>historical</td>\n",
       "      <td>1hr</td>\n",
       "      <td>cf</td>\n",
       "      <td>d03</td>\n",
       "      <td>s3://wfclimres/era/pv_distributed/ec-earth3/hi...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>pv_distributed</td>\n",
       "      <td>WRF</td>\n",
       "      <td>ERA</td>\n",
       "      <td>EC-Earth3</td>\n",
       "      <td>historical</td>\n",
       "      <td>1hr</td>\n",
       "      <td>gen</td>\n",
       "      <td>d03</td>\n",
       "      <td>s3://wfclimres/era/pv_distributed/ec-earth3/hi...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>pv_distributed</td>\n",
       "      <td>WRF</td>\n",
       "      <td>ERA</td>\n",
       "      <td>EC-Earth3</td>\n",
       "      <td>historical</td>\n",
       "      <td>day</td>\n",
       "      <td>cf</td>\n",
       "      <td>d03</td>\n",
       "      <td>s3://wfclimres/era/pv_distributed/ec-earth3/hi...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>pv_distributed</td>\n",
       "      <td>WRF</td>\n",
       "      <td>ERA</td>\n",
       "      <td>EC-Earth3</td>\n",
       "      <td>historical</td>\n",
       "      <td>day</td>\n",
       "      <td>gen</td>\n",
       "      <td>d03</td>\n",
       "      <td>s3://wfclimres/era/pv_distributed/ec-earth3/hi...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>pv_distributed</td>\n",
       "      <td>WRF</td>\n",
       "      <td>ERA</td>\n",
       "      <td>EC-Earth3</td>\n",
       "      <td>ssp370</td>\n",
       "      <td>1hr</td>\n",
       "      <td>cf</td>\n",
       "      <td>d03</td>\n",
       "      <td>s3://wfclimres/era/pv_distributed/ec-earth3/ss...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>107</th>\n",
       "      <td>windpower_onshore</td>\n",
       "      <td>WRF</td>\n",
       "      <td>ERA</td>\n",
       "      <td>MPI-ESM1-2-HR</td>\n",
       "      <td>ssp370</td>\n",
       "      <td>1hr</td>\n",
       "      <td>gen</td>\n",
       "      <td>d03</td>\n",
       "      <td>s3://wfclimres/era/windpower_onshore/mpi-esm1-...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>108</th>\n",
       "      <td>windpower_onshore</td>\n",
       "      <td>WRF</td>\n",
       "      <td>ERA</td>\n",
       "      <td>TaiESM1</td>\n",
       "      <td>historical</td>\n",
       "      <td>1hr</td>\n",
       "      <td>cf</td>\n",
       "      <td>d03</td>\n",
       "      <td>s3://wfclimres/era/windpower_onshore/taiesm1/h...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>109</th>\n",
       "      <td>windpower_onshore</td>\n",
       "      <td>WRF</td>\n",
       "      <td>ERA</td>\n",
       "      <td>TaiESM1</td>\n",
       "      <td>historical</td>\n",
       "      <td>1hr</td>\n",
       "      <td>gen</td>\n",
       "      <td>d03</td>\n",
       "      <td>s3://wfclimres/era/windpower_onshore/taiesm1/h...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>110</th>\n",
       "      <td>windpower_onshore</td>\n",
       "      <td>WRF</td>\n",
       "      <td>ERA</td>\n",
       "      <td>TaiESM1</td>\n",
       "      <td>ssp370</td>\n",
       "      <td>1hr</td>\n",
       "      <td>cf</td>\n",
       "      <td>d03</td>\n",
       "      <td>s3://wfclimres/era/windpower_onshore/taiesm1/s...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>111</th>\n",
       "      <td>windpower_onshore</td>\n",
       "      <td>WRF</td>\n",
       "      <td>ERA</td>\n",
       "      <td>TaiESM1</td>\n",
       "      <td>ssp370</td>\n",
       "      <td>1hr</td>\n",
       "      <td>gen</td>\n",
       "      <td>d03</td>\n",
       "      <td>s3://wfclimres/era/windpower_onshore/taiesm1/s...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>112 rows × 9 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "          installation activity_id institution_id      source_id  \\\n",
       "0       pv_distributed         WRF            ERA      EC-Earth3   \n",
       "1       pv_distributed         WRF            ERA      EC-Earth3   \n",
       "2       pv_distributed         WRF            ERA      EC-Earth3   \n",
       "3       pv_distributed         WRF            ERA      EC-Earth3   \n",
       "4       pv_distributed         WRF            ERA      EC-Earth3   \n",
       "..                 ...         ...            ...            ...   \n",
       "107  windpower_onshore         WRF            ERA  MPI-ESM1-2-HR   \n",
       "108  windpower_onshore         WRF            ERA        TaiESM1   \n",
       "109  windpower_onshore         WRF            ERA        TaiESM1   \n",
       "110  windpower_onshore         WRF            ERA        TaiESM1   \n",
       "111  windpower_onshore         WRF            ERA        TaiESM1   \n",
       "\n",
       "    experiment_id table_id variable_id grid_label  \\\n",
       "0      historical      1hr          cf        d03   \n",
       "1      historical      1hr         gen        d03   \n",
       "2      historical      day          cf        d03   \n",
       "3      historical      day         gen        d03   \n",
       "4          ssp370      1hr          cf        d03   \n",
       "..            ...      ...         ...        ...   \n",
       "107        ssp370      1hr         gen        d03   \n",
       "108    historical      1hr          cf        d03   \n",
       "109    historical      1hr         gen        d03   \n",
       "110        ssp370      1hr          cf        d03   \n",
       "111        ssp370      1hr         gen        d03   \n",
       "\n",
       "                                                  path  \n",
       "0    s3://wfclimres/era/pv_distributed/ec-earth3/hi...  \n",
       "1    s3://wfclimres/era/pv_distributed/ec-earth3/hi...  \n",
       "2    s3://wfclimres/era/pv_distributed/ec-earth3/hi...  \n",
       "3    s3://wfclimres/era/pv_distributed/ec-earth3/hi...  \n",
       "4    s3://wfclimres/era/pv_distributed/ec-earth3/ss...  \n",
       "..                                                 ...  \n",
       "107  s3://wfclimres/era/windpower_onshore/mpi-esm1-...  \n",
       "108  s3://wfclimres/era/windpower_onshore/taiesm1/h...  \n",
       "109  s3://wfclimres/era/windpower_onshore/taiesm1/h...  \n",
       "110  s3://wfclimres/era/windpower_onshore/taiesm1/s...  \n",
       "111  s3://wfclimres/era/windpower_onshore/taiesm1/s...  \n",
       "\n",
       "[112 rows x 9 columns]"
      ]
     },
     "execution_count": 146,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "b1 = Builder(paths=filepaths, depth=0, include_patterns=[\"**/.zmetadata\"])\n",
    "b1.build(parsing_func=parse_ae_ren_data)\n",
    "b1.clean_dataframe()\n",
    "b1.df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Method 2: Feed the Builder a directory containing your files \n",
    "In this method, this Builder will do some of the hard work for you by crawling through your directories looking for files matching your specifications. Thanks, Builder!<br><br>\n",
    "\n",
    "#### Notes on the \"depth\" Builder input\n",
    "In this case, the path to a file in our directory looks like this: `\"s3://wfclimres/era/pv_distributed/ec-earth3/historical/1hr/cf/d03/\"`<br>\n",
    "But, the path we are giving Builder looks like this: `\"s3://wfclimres/era/pv_distributed/\"`\n",
    "\n",
    "Thus, the `depth` for this Builder would  be `5`: We need to crawl through 5 different directories (`\"ec-earth3/historical/1hr/cf/d03/\"`) beyond the root directory to finally reach our zarr store. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 142,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/nicolekeeney/opt/anaconda3/envs/intake-esm-tools/lib/python3.10/site-packages/ecgtools/builder.py:208: UserWarning: Unable to parse 112 assets. A list of these assets can be found in `.invalid_assets` attribute.\n",
      "  ).clean_dataframe()\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>installation</th>\n",
       "      <th>activity_id</th>\n",
       "      <th>institution_id</th>\n",
       "      <th>source_id</th>\n",
       "      <th>experiment_id</th>\n",
       "      <th>table_id</th>\n",
       "      <th>variable_id</th>\n",
       "      <th>grid_label</th>\n",
       "      <th>path</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>pv_distributed</td>\n",
       "      <td>WRF</td>\n",
       "      <td>ERA</td>\n",
       "      <td>EC-Earth3</td>\n",
       "      <td>historical</td>\n",
       "      <td>1hr</td>\n",
       "      <td>cf</td>\n",
       "      <td>d03</td>\n",
       "      <td>s3://wfclimres/era/pv_distributed/ec-earth3/hi...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>pv_distributed</td>\n",
       "      <td>WRF</td>\n",
       "      <td>ERA</td>\n",
       "      <td>EC-Earth3</td>\n",
       "      <td>historical</td>\n",
       "      <td>1hr</td>\n",
       "      <td>gen</td>\n",
       "      <td>d03</td>\n",
       "      <td>s3://wfclimres/era/pv_distributed/ec-earth3/hi...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>pv_distributed</td>\n",
       "      <td>WRF</td>\n",
       "      <td>ERA</td>\n",
       "      <td>EC-Earth3</td>\n",
       "      <td>historical</td>\n",
       "      <td>day</td>\n",
       "      <td>cf</td>\n",
       "      <td>d03</td>\n",
       "      <td>s3://wfclimres/era/pv_distributed/ec-earth3/hi...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>pv_distributed</td>\n",
       "      <td>WRF</td>\n",
       "      <td>ERA</td>\n",
       "      <td>EC-Earth3</td>\n",
       "      <td>historical</td>\n",
       "      <td>day</td>\n",
       "      <td>gen</td>\n",
       "      <td>d03</td>\n",
       "      <td>s3://wfclimres/era/pv_distributed/ec-earth3/hi...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>pv_distributed</td>\n",
       "      <td>WRF</td>\n",
       "      <td>ERA</td>\n",
       "      <td>EC-Earth3</td>\n",
       "      <td>ssp370</td>\n",
       "      <td>1hr</td>\n",
       "      <td>cf</td>\n",
       "      <td>d03</td>\n",
       "      <td>s3://wfclimres/era/pv_distributed/ec-earth3/ss...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>215</th>\n",
       "      <td>windpower_onshore</td>\n",
       "      <td>WRF</td>\n",
       "      <td>ERA</td>\n",
       "      <td>MPI-ESM1-2-HR</td>\n",
       "      <td>ssp370</td>\n",
       "      <td>1hr</td>\n",
       "      <td>gen</td>\n",
       "      <td>d03</td>\n",
       "      <td>s3://wfclimres/era/windpower_onshore/mpi-esm1-...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>217</th>\n",
       "      <td>windpower_onshore</td>\n",
       "      <td>WRF</td>\n",
       "      <td>ERA</td>\n",
       "      <td>TaiESM1</td>\n",
       "      <td>historical</td>\n",
       "      <td>1hr</td>\n",
       "      <td>cf</td>\n",
       "      <td>d03</td>\n",
       "      <td>s3://wfclimres/era/windpower_onshore/taiesm1/h...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>219</th>\n",
       "      <td>windpower_onshore</td>\n",
       "      <td>WRF</td>\n",
       "      <td>ERA</td>\n",
       "      <td>TaiESM1</td>\n",
       "      <td>historical</td>\n",
       "      <td>1hr</td>\n",
       "      <td>gen</td>\n",
       "      <td>d03</td>\n",
       "      <td>s3://wfclimres/era/windpower_onshore/taiesm1/h...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>221</th>\n",
       "      <td>windpower_onshore</td>\n",
       "      <td>WRF</td>\n",
       "      <td>ERA</td>\n",
       "      <td>TaiESM1</td>\n",
       "      <td>ssp370</td>\n",
       "      <td>1hr</td>\n",
       "      <td>cf</td>\n",
       "      <td>d03</td>\n",
       "      <td>s3://wfclimres/era/windpower_onshore/taiesm1/s...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>223</th>\n",
       "      <td>windpower_onshore</td>\n",
       "      <td>WRF</td>\n",
       "      <td>ERA</td>\n",
       "      <td>TaiESM1</td>\n",
       "      <td>ssp370</td>\n",
       "      <td>1hr</td>\n",
       "      <td>gen</td>\n",
       "      <td>d03</td>\n",
       "      <td>s3://wfclimres/era/windpower_onshore/taiesm1/s...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>112 rows × 9 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "          installation activity_id institution_id      source_id  \\\n",
       "1       pv_distributed         WRF            ERA      EC-Earth3   \n",
       "3       pv_distributed         WRF            ERA      EC-Earth3   \n",
       "5       pv_distributed         WRF            ERA      EC-Earth3   \n",
       "7       pv_distributed         WRF            ERA      EC-Earth3   \n",
       "9       pv_distributed         WRF            ERA      EC-Earth3   \n",
       "..                 ...         ...            ...            ...   \n",
       "215  windpower_onshore         WRF            ERA  MPI-ESM1-2-HR   \n",
       "217  windpower_onshore         WRF            ERA        TaiESM1   \n",
       "219  windpower_onshore         WRF            ERA        TaiESM1   \n",
       "221  windpower_onshore         WRF            ERA        TaiESM1   \n",
       "223  windpower_onshore         WRF            ERA        TaiESM1   \n",
       "\n",
       "    experiment_id table_id variable_id grid_label  \\\n",
       "1      historical      1hr          cf        d03   \n",
       "3      historical      1hr         gen        d03   \n",
       "5      historical      day          cf        d03   \n",
       "7      historical      day         gen        d03   \n",
       "9          ssp370      1hr          cf        d03   \n",
       "..            ...      ...         ...        ...   \n",
       "215        ssp370      1hr         gen        d03   \n",
       "217    historical      1hr          cf        d03   \n",
       "219    historical      1hr         gen        d03   \n",
       "221        ssp370      1hr          cf        d03   \n",
       "223        ssp370      1hr         gen        d03   \n",
       "\n",
       "                                                  path  \n",
       "1    s3://wfclimres/era/pv_distributed/ec-earth3/hi...  \n",
       "3    s3://wfclimres/era/pv_distributed/ec-earth3/hi...  \n",
       "5    s3://wfclimres/era/pv_distributed/ec-earth3/hi...  \n",
       "7    s3://wfclimres/era/pv_distributed/ec-earth3/hi...  \n",
       "9    s3://wfclimres/era/pv_distributed/ec-earth3/ss...  \n",
       "..                                                 ...  \n",
       "215  s3://wfclimres/era/windpower_onshore/mpi-esm1-...  \n",
       "217  s3://wfclimres/era/windpower_onshore/taiesm1/h...  \n",
       "219  s3://wfclimres/era/windpower_onshore/taiesm1/h...  \n",
       "221  s3://wfclimres/era/windpower_onshore/taiesm1/s...  \n",
       "223  s3://wfclimres/era/windpower_onshore/taiesm1/s...  \n",
       "\n",
       "[112 rows x 9 columns]"
      ]
     },
     "execution_count": 142,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "root_dir = 's3://wfclimres/era/'\n",
    "installations = [\"pv_distributed\", \"pv_utility\", \"windpower_offshore\", \"windpower_onshore\"]\n",
    "exclude_patterns = [\n",
    "    \"**/EC-Earth3/**\", \n",
    "    \"**/ERA5/**\", \n",
    "    \"**/MIROC6/**\", \n",
    "    \"**/MPI-ESM1-2-HR/**\", \n",
    "    \"**TaiESM1/**\"\n",
    "    ]\n",
    "b2 = Builder(\n",
    "    paths=[f's3://wfclimres/era/{installation}/' for installation in installations], \n",
    "    depth=5, \n",
    "    exclude_patterns=exclude_patterns, \n",
    "    include_patterns=[\"**/.zmetadata\"]\n",
    ")\n",
    "b2.build(parsing_func=parse_ae_ren_data)\n",
    "b2.clean_dataframe()\n",
    "b2.df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Method 2b: Feed the Builder your entire bucket (slow and untested)\n",
    "In theory, you can also just feed the builder the entire bucket and have it crawl through everything. However, this method is really slow-- I haven't actually been patient enough to wait for the code to complete running, so I have it commented out below. I'm leaving it here for documentation's sake, in case it is useful for other s3 buckets in the future. \n",
    "\n",
    "#### Notes on the \"depth\" Builder input\n",
    "In this case, the path to a file in our directory looks like this: `\"s3://wfclimres/era/pv_distributed/ec-earth3/historical/1hr/cf/d03/\"`<br>\n",
    "But, the path we are giving Builder looks like this: `\"s3://wfclimres/era/\"`\n",
    "\n",
    "Thus, the `depth` for this Builder would  be `6`: We need to crawl through 6 different directories (`\"pv_distributed/ec-earth3/historical/1hr/cf/d03/\"`) beyond the root directory to finally reach our zarr store. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# exclude_patterns = [\n",
    "#     \"s3://wfclimres/era/derived_products/**\",\n",
    "#     \"s3://wfclimres/era/resource_data/**\",\n",
    "#     \"s3://wfclimres/era/rsrc_drought/**\",\n",
    "#     \"s3://wfclimres/era/tmp/**\",\n",
    "#     \"s3://wfclimres/era/data-guide_pv-wind.pdf\"\n",
    "#     \"**/EC-Earth3/**\", \n",
    "#     \"**/ERA5/**\", \n",
    "#     \"**/MIROC6/**\", \n",
    "#     \"**/MPI-ESM1-2-HR/**\", \n",
    "#     \"**TaiESM1/**\"\n",
    "#     ]\n",
    "# b3 = Builder(\n",
    "#     paths=[\"s3://wfclimres/era/\"], \n",
    "#     depth=6, \n",
    "#     exclude_patterns=exclude_patterns, \n",
    "#     include_patterns=[\"**/.zmetadata\"]\n",
    "# )\n",
    "# b3.build(parsing_func=parse_ae_ren_data)\n",
    "# b3.clean_dataframe()\n",
    "# b3.df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Confirm that these methods are equal \n",
    "If everything went as expected, methods 1 and 2 should return the same result. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 149,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Need to reset the index on the second Builder since it's not ordered appropriately for some reason \n",
    "b1.df.equals(b2.df.reset_index(drop=True))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 3: Export the catalog \n",
    "We need to export `csv` and `json` files associated with our built catalog. We also need to set the data aggregations which are fed into xarray when reading in data using intake"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "b1.save(\n",
    "    name='ae-ren',\n",
    "    directory='../catalogs/ae-ren/',\n",
    "    # Column name including filepath\n",
    "    path_column_name='path',\n",
    "    # Column name including variables\n",
    "    variable_column_name='variable',\n",
    "    # Data file format - could be netcdf or zarr (in this case, netcdf)\n",
    "    data_format=\"netcdf\",\n",
    "    # Which attributes to groupby when reading in variables using intake-esm\n",
    "    groupby_attrs=[\"component\", \"stream\", \"case\"],\n",
    "    # Aggregations which are fed into xarray when reading in data using intake\n",
    "    aggregations=[\n",
    "        {'type': 'union', 'attribute_name': 'variable'},\n",
    "        {\n",
    "            \"type\": \"join_existing\",\n",
    "            \"attribute_name\": \"time_range\",\n",
    "            \"options\": {\"dim\": \"time\", \"coords\": \"minimal\", \"compat\": \"override\"},\n",
    "        },\n",
    "    ],\n",
    ")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "intake-esm-tools",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
